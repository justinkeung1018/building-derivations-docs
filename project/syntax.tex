\chapter{Syntax rules}
\label{chapter:syntax}
\section{Syntax of syntax rules}
\label{syntax:syntax}
A syntax rule consists of:
\begin{itemize}
    \item a list of comma-separated \textbf{placeholders}, and
    \item a \textbf{definition}, consisting of one or more non-empty alternatives separated by vertical bars \lstinline{|} 
\end{itemize}
In rule definitions, curly braces \lstinline|{}| represent a multiset. The structure of each element of a multiset is defined by the content enclosed within the curly braces. For example, the definition \lstinline|{ M: A }| represents a possibly empty collection of possibly duplicate elements following the structure \lstinline{M: A}.

Every valid syntax definition (i.e. collection of syntax rules) must contain at least one rule for a statement. A valid syntax definition can contain multiple rules for a statement. All non-statement rules must specify placeholders. Otherwise, there is no way to refer to the definition of such rules and they might as well be removed from the syntax definition.

The only special character in the definition of placeholders is the comma. The special characters in the definition of a syntax rule are the vertical bar \lstinline{|} and the curly braces \lstinline|{}|. Unlike in EBNF, characters like parentheses \lstinline{()} and brackets \lstinline{[]} do not carry any special meaning anywhere in this system and are no different from any other ordinary character. Certain groups of characters, such as \lstinline{|-} and \lstinline{->}, are treated as one symbol and shorthands for \LaTeX{} commands, such as \lstinline{\vdash} and \lstinline{\rightarrow}.

A rule definition can refer to itself or other rules by their placeholders. In the definition of syntax rules, there is no difference using one placeholder over another to refer to the same rule. For example, given the placeholders \lstinline{A} and \lstinline{B} for a rule, the definitions \lstinline{(A -> A)}, \lstinline{(B -> B)}, \lstinline{(A -> B)}, and \lstinline{(B -> A)} are all identical. However, it is useful to have multiple placeholders because in inference rules, placeholders are treated as names representing concrete objects.

\section{User interface}

\section{Parsing syntax rules}
The aim of this step is to generate a list of \lstinline{Token}s for each rule alternative, and thus a two-dimensional array of \lstinline{Token}s for each rule definition. These \lstinline{Token}s will be used to generate term parsers, i.e. parsers for parsing instances of each rule.

\subsection{Tokens}
The tokens are defined as follows:
\begin{lstlisting}
    class Terminal { constructor(readonly value: string) {} }
    class NonTerminal { constructor(readonly index: number) {} }
    class Multiset { constructor(readonly tokens: Token[]) {} }
    class Or { constructor(readonly alternatives: Token[][]) {} }
    class Maybe { constructor(readonly alternatives: Token[][]) {} }

    type Token = Terminal | NonTerminal | Multiset | Or | Maybe;
\end{lstlisting}
The \lstinline{index} field of \lstinline{NonTerminal} is the rule number of the placeholder. For example, if a syntax definition contains two rules
\begin{align*}
    S &\Coloneqq \ldots \\
    A, B &\Coloneqq \ldots
\end{align*}
Then any occurrences of the placeholder $S$ are represented by a \lstinline{NonTerminal} with \lstinline{index} 0 and any occurrences of either of the placeholders $A$ or $B$ are represented by a \lstinline{NonTerminal} with \lstinline{index} 1.

The \lstinline{tokens} field of \lstinline{Multiset} defines the structure of an element of the multiset. For example, consider a rule definition that contains a multiset:
\begin{align*}
    S &\Coloneqq \{ var: A \}
\end{align*}
Assuming $var$ and $A$ are placeholders, the rule definition is represented by a \lstinline{Multiset} with \lstinline{tokens} field set to something like \lstinline{[NonTerminal(...), Terminal(":"), NonTerminal(...)]}.

The \lstinline{Or} and \lstinline{Maybe} tokens are only generated by the factorisation algorithm, as described in \Cref{syntax:factorisation}.

\subsection{Procedure}
The process consists of three steps.

\subsubsection{Splitting placeholders and alternatives of rule definitions}
When the backend receives user input from the frontend, every rule is specified by a string representing the placeholders and a string representing the definition. The placeholder string is split on commas to give a list of placeholders. To preprocess the definition string, all occurrences of \lstinline{|-} are replaced with \lstinline{\vdash}, the \LaTeX{} command for a turnstile, then the string is split on vertical bars \lstinline{|} to give a list of alternatives. The replacement is necessary and correct as \lstinline{|-} contains a vertical bar \lstinline{|} while \lstinline{\vdash} does not.

\subsubsection{Normalise placeholders and rule definitions}
Aliases of a symbol are unified. For example, the symbol for an arrow \lstinline{->} can be represented by \lstinline{\rightarrow}, \lstinline{\to}, \lstinline{->}, and the Unicode character â†’. In this case, all aliases are replaced with \lstinline{->} (other than having the fewest characters and better readability, the choice is entirely arbitrary). Prior to the replacements, a space is added after all substrings that resemble a \LaTeX{} command, i.e. any substring beginning with \lstinline{\} and a string of non-whitespace characters. This ensures we do not accidentally replace parts of a \LaTeX{} command and e.g. turn \lstinline{\toI} into \lstinline{->I}. The user may have intended the latter, but the former is a typo nonetheless.

\subsubsection{Generate parser}
The parser outputs three types of tokens: \lstinline{Terminal}, \lstinline{NonTerminal}, and \lstinline{Multiset}. The final parser tries to match a non-terminal, then (if it fails) a multiset, then (if both fail) a terminal. Each of these sub-parsers is generated as follows:
\begin{itemize}
    \item \lstinline{Terminal}: it matches, in descending order of priority, any string that resembles a \LaTeX{} command, any special group of characters e.g. \lstinline{|-} and \lstinline{->}, or any single character.
    \item \lstinline{NonTerminal}: it matches any placeholder across all rules in descending order of length.
    \item \lstinline{Multiset}: it matches a sequence of zero or more \lstinline{Terminal}s or \lstinline{NonTerminal}s enclosed within curly braces \lstinline|{}|. The empty multiset definition \lstinline|{}| is technically valid but not very useful: the user can only supply the empty set or a string of commas.
\end{itemize}

\subsubsection{Factorise rule definitions}
\label{syntax:factorisation}
The need for this step is primarily motivated by the idiosyncrasies of \lstinline{parjs}, particularly its \lstinline{then} combinator, as explained in \Cref{parsing:thenor}. 

The factorisation algorithm takes a list of alternatives, each of which is represented by a list of tokens (\lstinline{Terminal}, \lstinline{NonTerminal}, or \lstinline{Multiset}), and outputs a new list of alternatives such that no two alternatives share a prefix. The algorithm is as follows:
\begin{enumerate}
    \item Partition the alternatives by their leading tokens. All alternatives beginning with the same \lstinline{Terminal} or \lstinline{NonTerminal} are grouped together. Recall that \lstinline{NonTerminal}s only stores the rule number and not the placeholder, so multiple alternatives beginning with different placeholders for the same rule are grouped together. Each partition now corresponds to a new alternative, because it does not share a leading token with any other partition. Since every member of a partition share a leading token, the new alternative correspodning to the partition must begin with that token. 
    \item Remove the first token from every member of every partition and recursively factorise each partition.
\end{enumerate}
Notice that the partitioning ignores \lstinline{Multiset} tokens. The algorithm assumes the definition of a multiset element does not share a leading token with any other alternative as it is otherwise difficult to handle:
\begin{itemize}
    \item If it shares a leading token with another multiset element, after the term parser parses one element and determines which multiset alternative the element belongs to, it must only accept this alternative from the second element onwards. It would be incorrect to treat the alternatives \lstinline|{ ab }| and \lstinline|{ ac }| as \lstinline*{ a(b|c) }* (by abuse of EBNF notation).
    \item The case where it shares a leading token with a non-multiset alternative is a variation of the case above. If the term parser parses a multiset 
\end{itemize}
Both of these cases are intentionally unsupported as they rarely occur. In the case of \lstinline{NonTerminal}s, the algorithm does not handle the case where different rules have non-disjoint \textit{first sets}. The \textit{first set} of a set of alternatives is the set containing every leading token of every alternative\footnote{If an alternative begins with a \lstinline{Terminal}, its contribution to the first set is the \lstinline{Terminal}. If an alternative begins with a \lstinline{NonTerminal}, its contribution to the first set is the first set of that \lstinline{NonTerminal}. If an alternative begins with a \lstinline{Multiset}, its contribution to the first set is the contribution of the first token of the element definition.}. For example, given the following rules:
\begin{align*}
    S &\Coloneqq Axx \alt Byy \\
    A &\Coloneqq x \alt y \\
    B &\Coloneqq x \alt z
\end{align*}
the factorisation algorithm would throw an error because \lstinline{A} and \lstinline{B} refer to different rules but have non-disjoint first sets. This scenario occurs more frequently and naturally than the previous case. Consider a more verbose formulation of the syntax of $\lambda$-terms:
\begin{align*}
    M, N &\Coloneqq \nonterm{var} \alt \nonterm{abstraction} \alt \nonterm{application} \\
    \nonterm{var} &\Coloneqq x \alt y \alt z \\
    \nonterm{abstraction} &\Coloneqq (\lambda x. M) \\
    \nonterm{application} &\Coloneqq (MN)
\end{align*}
The alternatives $\nonterm{abstraction}$ and $\nonterm{application}$ share non-disjoint first sets but belong to different rules. The factorisation algorithm would throw an error at this formulation.

One solution is to recursively replace every offending \lstinline{NonTerminal} with each of the \lstinline{NonTerminal}'s alternative definitions, but this destroys the original structure of the syntax rules and greatly complicates bookkeeping. Throwing an error instead of algorithmically handling this case forces the user to rewrite the syntax rules and allows the parsing result to resemble the original structure of the syntax rules as closely as possible.

In addition to the three types of tokens previously mentioned (\lstinline{Terminal}, \lstinline{NonTerminal}, and \lstinline{Multiset}), the factorisation algorithm may output two more types of tokens: \lstinline{Or} and \lstinline{Maybe}. The semantics of the new tokens is best illustrated through the examples in \Cref{table:factorisation}.

\begin{table}
    \centering
    \caption{The factorisation algorithm applied to various rule definitions}
    \begin{tblr}{ll}
        \toprule
        Rule definition & Factorisation output \\
        \midrule
        \lstinline{ab | ac} & \lstinline{[Terminal("a"), Or([Terminal("b")], [Terminal("c")])]} \\
        \lstinline{a | ab} & \lstinline{[Terminal("a"), Maybe([[Terminal("b")]])]} \\
        \lstinline{a | ab | ac} & \lstinline{[Terminal("a"), Maybe([[Terminal("b")][Terminal("c")]])]} \\
        \bottomrule
    \end{tblr}
    \label{table:factorisation}
\end{table}

The beginning of this section notes that after parsing, each rule definition becomes a two-dimensional array of tokens, in which each element (a one-dimensional array of tokens) represents a parsed rule alternative. One could also represent a collection of top-level alternatives as an \lstinline{Or} token. Here, the two-dimensional array is chosen over the top-level \lstinline{Or} token to distinguish between the output of the parsing step and the output of the factorisation algorithm, though otherwise the choice is arbitrary.

\section{Limitations}
\subsection{Placeholders cannot be used as terminals}
Suppose a user tries to define the syntax of $\lambda$-terms:
\begin{align*}
    M, N &\Coloneqq x \alt (\lambda x. M) \alt (MN) \\
    x &\Coloneqq x \alt y \alt z
\end{align*}
The second rule is necessary as the system does not ``know'' $x$ in the first rule is a variable: if a character is not a placeholder, it is treated as a \lstinline{Terminal}. However, contrary to what the user expects, the $x$ in the first alternative of the second rule is interpreted as a reference to its own rule. Since it is the first token of the alternative, the alternative is considered left-recursive by the parsing algorithm and causes the parsing algorithm to throw an error. The current workaround to this issue is as follows:
\begin{align*}
    M, N &\Coloneqq var \alt (\lambda var. M) \alt (MN) \\
    var &\Coloneqq x \alt y \alt z
\end{align*}
The use of $var$ is unconventional and differs from most textbook formulations. However, there is no good way to tell the parsing algorithm to treat $x$ as a literal string instead of a placeholder depending on where it appears. One solution is to treat lowercase placeholders as literal strings if it appears in the definition of its own rule and placeholders otherwise. However, this solution not only makes the system prejudiced against certain inputs, but is also equally problematic. A frustrated user may find the following definition of Curry types to be interpreted rather unexpectedly:
\[
  a, b \Coloneqq \varphi \alt (a \to b)
\]